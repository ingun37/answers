{"parentSha1":"b0472f3d9a6f8b52b80c5d4303f31bd8eeb95ff8","path":"books/Neural Networks and Deep Learning/2. How the backpropagation algorithm works/The four fundamental equations behind backpropagation/Alternate presentation of the equations of backpropagation/1","item":{"title":"1","attr":{"q":"Show that (BP1) may be rewritten as\n\n```math\n\\delta^L = \\Sigma'(z^L) \\nabla_a C\n\\tag{33}\n```\n\nwhere $`\\Sigma'(z^L)`$ is a square matrix whose diagonal entries are the values $`\\sigma'(z^L_j)`$, and whose off-diagonal entries are zero. Note that this matrix acts on $`\\nabla_a C`$ by conventional matrix multiplication.","a":"We can either prove it by using properties of diagonal matrices or using the chain rule of gradient. Former one is rather mundane so I'll go with latter one.\n\n$`\\delta_l`$ is gradient of $`C`$ in terms of $`z_l`$, namely\n\n```math\n\\delta^l = \\nabla_{z_l} C\n```\n\nSince $`a_l = \\sigma(z_l)`$, we can apply chain rule with Jacobian matrix.\n\n```math\n\\nabla_{z_l} C = {J_\\sigma (z_l)}^\\intercal \\nabla_{a_l} C \n```\n\nWhen the function is element-wise operation the Jacobian matrix becomes a diagonal matrix. $`\\sigma`$ is elementwise function therefore the Jacobian matrix becomes exactly the matrix that was given in the question.\n\n```math\n= {\\Sigma' (z_l)}^\\intercal \\nabla_{a_l} C \n```\n\nTranspose doesn't change diagonal matrices so\n\n```math\n= {\\Sigma' (z_l)} \\nabla_{a_l} C \n```"},"sha1":"cb91e3c897f441cd40064631250662d0ff548040"},"kids":[]}