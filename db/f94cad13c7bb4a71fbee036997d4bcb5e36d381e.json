{
    "item": {
        "attr": {
            "a": {
                "content": "<p>We've already proved that Hadamard productinng <span\nclass=\"math inline\">\\sigma &#39; (z_l)</span> is equal to multiplying\n<span class=\"math inline\">\\Sigma &#39; (z_l)</span>, and <span\nclass=\"math inline\">\\Sigma &#39; (z_l)</span> can move it's\nmultiplicative position. Rearranging the result of (2) we get</p>\n<p><span class=\"math display\">\\delta_l = W^\\intercal \\delta_{l+1} \\odot\n\\sigma &#39; (z_l) = W^\\intercal \\Sigma &#39; (z_l)\n\\delta_{l+1}</span></p>\n<p>which is recursive expression with the initial value of <span\nclass=\"math inline\">\\delta^L = \\Sigma&#39;(z^L) \\nabla_a C</span>. We\nget the expression from the question when we serialize this recursive\nexpression.</p>",
                "posixTime": 1592193923
            },
            "q": {
                "content": "<p>By combining observations (1) and (2) show that</p>\n<p><span class=\"math display\">\\delta^l = \\Sigma&#39;(z^l) (w^{l+1})^T\n\\ldots \\Sigma&#39;(z^{L-1}) (w^L)^T\n    \\Sigma&#39;(z^L) \\nabla_a C\n  \\tag{35}</span></p>",
                "posixTime": 1592193923
            }
        },
        "numAnswer": 1,
        "sha1": "f94cad13c7bb4a71fbee036997d4bcb5e36d381e",
        "title": "3"
    },
    "kids": [],
    "parentSha1": "6ed65dadd1a6039b895159d69c1c0d8be2959671",
    "path": "answers-db/books/Neural Networks and Deep Learning/2. How the backpropagation algorithm works/The four fundamental equations behind backpropagation/Alternate presentation of the equations of backpropagation/3"
}