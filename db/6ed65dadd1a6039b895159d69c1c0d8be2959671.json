{
    "item": {
        "attr": {
            "q": {
                "content": "<p>I've stated the equations of backpropagation (notably (BP1) and\n(BP2)) using the Hadamard product. This presentation may be\ndisconcerting if you're unused to the Hadamard product. There's an\nalternative approach, based on conventional matrix multiplication, which\nsome readers may find enlightening.</p>",
                "posixTime": 1678612923
            }
        },
        "numAnswer": 3,
        "sha1": "6ed65dadd1a6039b895159d69c1c0d8be2959671",
        "title": "Alternate presentation of the equations of backpropagation"
    },
    "kids": [
        {
            "attr": {
                "a": {
                    "content": "<p>We can either prove it by using properties of diagonal matrices or\nusing the chain rule of gradient. Former one is rather mundane so I'll\ngo with latter one.</p>\n<p><span class=\"math inline\">\\delta_l</span> is gradient of <span\nclass=\"math inline\">C</span> in terms of <span\nclass=\"math inline\">z_l</span>, namely</p>\n<p><span class=\"math display\">\\delta^l = \\nabla_{z_l} C</span></p>\n<p>Since <span class=\"math inline\">a_l = \\sigma(z_l)</span>, we can\napply chain rule with Jacobian matrix.</p>\n<p><span class=\"math display\">\\nabla_{z_l} C = {J_\\sigma\n(z_l)}^\\intercal \\nabla_{a_l} C</span></p>\n<p>When the function is element-wise operation the Jacobian matrix\nbecomes a diagonal matrix. <span class=\"math inline\">\\sigma</span> is\nelementwise function therefore the Jacobian matrix becomes exactly the\nmatrix that was given in the question.</p>\n<p><span class=\"math display\">= {\\Sigma&#39; (z_l)}^\\intercal\n\\nabla_{a_l} C</span></p>\n<p>Transpose doesn't change diagonal matrices so</p>\n<p><span class=\"math display\">= {\\Sigma&#39; (z_l)} \\nabla_{a_l}\nC</span></p>",
                    "posixTime": 1678612923
                },
                "q": {
                    "content": "<p>Show that (BP1) may be rewritten as</p>\n<p><span class=\"math display\">\\delta^L = \\Sigma&#39;(z^L) \\nabla_a C\n\\tag{33}</span></p>\n<p>where <span class=\"math inline\">\\Sigma&#39;(z^L)</span> is a square\nmatrix whose diagonal entries are the values <span\nclass=\"math inline\">\\sigma&#39;(z^L_j)</span>, and whose off-diagonal\nentries are zero. Note that this matrix acts on <span\nclass=\"math inline\">\\nabla_a C</span> by conventional matrix\nmultiplication.</p>",
                    "posixTime": 1678612923
                }
            },
            "numAnswer": 1,
            "sha1": "6f70934e588d04e883d816fe5be976f96aba3cf9",
            "title": "1"
        },
        {
            "attr": {
                "a": {
                    "content": "<p>Just like the previous question, we can either prove it by using\nproperties of diagonal matrices or applying one more chian rule to the\nanswer of previous question. I'll go with latter one again.</p>\n<p>Let <span class=\"math inline\">T</span> be the function of multiplying\nand adding weights and biases.</p>\n<p><span class=\"math display\">T(a) = Wa + B</span></p>\n<p>Then we can define <span class=\"math inline\">z_{l+1}</span> in terms\nof <span class=\"math inline\">z_l</span>.</p>\n<p><span class=\"math display\">z_{l+1} = T \\circ \\sigma (z_l)</span></p>\n<p>Jacobian of <span class=\"math inline\">T \\circ \\sigma</span> is (chain\nrule)</p>\n<p><span class=\"math display\">J_{T \\sigma} = J_T (a_l) J_\\sigma\n(z_l)</span></p>\n<p>where <span class=\"math inline\">J_\\sigma (z_l)</span> is <span\nclass=\"math inline\">\\Sigma &#39; (z_l)</span> (proven in the previous\nproblem) and <span class=\"math inline\">J_T (a_l) = W</span> (because of\nlinearity). Therefore we can simplify like this</p>\n<p><span class=\"math display\">= W \\Sigma &#39; (z_l)</span></p>\n<p>We are already given the gradient of <span\nclass=\"math inline\">C</span> in terms of <span\nclass=\"math inline\">z_{l+1}</span> which is <span\nclass=\"math inline\">\\delta_{l+1}</span>, therefore</p>\n<p><span class=\"math display\">\\begin{aligned}\n    \\delta_l &amp;= \\left( W \\Sigma &#39; (z_l) \\right)^\\intercal\n\\delta_{l+1} \\\\\n             &amp;= W^\\intercal \\Sigma &#39; (z_l)^\\intercal\n\\delta_{l+1} \\\\\n\\end{aligned}</span></p>\n<p>Since <span class=\"math inline\">\\Sigma &#39; (z_l)</span> is diagonal\nwe can remove the transpose and move it to the end and turn into\nHadamard product.</p>\n<p><span class=\"math display\">= W^\\intercal \\delta_{l+1} \\odot \\sigma\n&#39; (z_l)</span></p>",
                    "posixTime": 1678612923
                },
                "q": {
                    "content": "<p>Show that (BP2) may be rewritten as</p>\n<p><span class=\"math display\">\\delta^l = \\Sigma&#39;(z^l) (w^{l+1})^T\n\\delta^{l+1} \\tag{34}</span></p>",
                    "posixTime": 1678612923
                }
            },
            "numAnswer": 1,
            "sha1": "600d0c672155d4021896a9f2ac1e685dc5ad0b5f",
            "title": "2"
        },
        {
            "attr": {
                "a": {
                    "content": "<p>We've already proved that Hadamard productinng <span\nclass=\"math inline\">\\sigma &#39; (z_l)</span> is equal to multiplying\n<span class=\"math inline\">\\Sigma &#39; (z_l)</span>, and <span\nclass=\"math inline\">\\Sigma &#39; (z_l)</span> can move it's\nmultiplicative position. Rearranging the result of (2) we get</p>\n<p><span class=\"math display\">\\delta_l = W^\\intercal \\delta_{l+1} \\odot\n\\sigma &#39; (z_l) = W^\\intercal \\Sigma &#39; (z_l)\n\\delta_{l+1}</span></p>\n<p>which is recursive expression with the initial value of <span\nclass=\"math inline\">\\delta^L = \\Sigma&#39;(z^L) \\nabla_a C</span>. We\nget the expression from the question when we serialize this recursive\nexpression.</p>",
                    "posixTime": 1678612923
                },
                "q": {
                    "content": "<p>By combining observations (1) and (2) show that</p>\n<p><span class=\"math display\">\\delta^l = \\Sigma&#39;(z^l) (w^{l+1})^T\n\\ldots \\Sigma&#39;(z^{L-1}) (w^L)^T\n    \\Sigma&#39;(z^L) \\nabla_a C\n  \\tag{35}</span></p>",
                    "posixTime": 1678612923
                }
            },
            "numAnswer": 1,
            "sha1": "f94cad13c7bb4a71fbee036997d4bcb5e36d381e",
            "title": "3"
        }
    ],
    "parentSha1": "5444b17082a3413816dcfce1721f581c2c2f07f2",
    "path": "answers-db/books/Neural Networks and Deep Learning/2. How the backpropagation algorithm works/The four fundamental equations behind backpropagation/Alternate presentation of the equations of backpropagation"
}